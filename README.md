# Subjective-Dissimilarity-and-Discrimination-Capacity 
 
This is the repository for the paper **Is subjective perceptual similarity metacognitive?** It is broken down into several directories, listed below. Each section will be described in more detail.
    
   
  
- **Analysis Code** - Used for analyzing and making plots from the collected data.

- **Collected Data** - Log files gathered from subjects while running the experiment. 

- **Near Threshold Discrimination Task/src** - Source code for the near-threshold discrimination task. 

- **Prepare Faces and Morphs** - Source code used to prepare the faces and morphs for the tasks. 

- **Subjective Similarity Judgment Task** - Source code for the subjective similarity judgment task.

     
         
The **pilot** folder contains all the codes and materials used in running our pilot study (N = 4 participants), all the data collected, and the analysis code ran on the data. 
The **Main** folder contains all the codes and materials that will be used in the main study. 
## Near Threshold Discrimination Task
The near-threshold discrimination task is an interleaved staircase task where subjects discriminate between morphs of selected face pairs. Each staircase represents one face pair with 1000 morphs between them. Each face is assigned an integer ID. For example, for the face pair `1-28`, `1-28.1` represents the first morph for this pair, which is the closest to face 1. Similarly, `1-28.1000` is the 1000th morph for this pair, which is the closet to face 28. In each iteration, the staircase shows three faces. It randomly chooses a morph *n*, and shows the morph with ID `n` twice. It also stores an integer distance *k*, also known as the intensity, to use for each iteration, and shows a morph which is *k* away from the face *n*, i.e. `n±k`, once. Whether the applied intensity is positive or negative is chosen at random. The range from which *n* is randomly chosen is constrained such that `n±k` will always be between 1 and 1000. The intensity is controlled by a set of rules passed to `StairHandlerGetIntensity`, which in this experiment specifies a 2-down/1-up staircase with decreasing step sizes upon reversals. 

The experiment tests multiple face pairs at once. Each of the face pairs is represented by one staircase, and these staircases are interleaved such that they are shown in a random sequence to the subject. In every iteration, each staircase is shown once. At the end of the iteration, the order of the staircases is shuffled. Then, the next iteration begins. This process is repeated until the number of iterations `exp_info["n_trials"]` is hit.

### Logging
Logging is done manually, with both an `experiment.csv` log which records information about each click, and an individual log per staircase which tracks responses, reversals, and intensities for the individual staircase.

The `experiment.csv` log is generated by saving information from every click to a list object `experiment_log_tracker`, which is written to a CSV at the end of each iteration. 

The staircase log is handled by the `StaircaseLogger` class, which writes reversals and responses. This is also written at the end of each iteration. Note that the staircase log is written with the labels as rows, while the `experiment.csv` log is written with the labels as columns. This was done because the built-in PsychoPy staircase logging uses row-based labeling.

### PsychoPy
This experiment runs on PsychoPy 2023, using Python version 3.8. 

## Subjective Similarity Judgment Task
The subjective similarity judgment task is a similarity task where subjects rank candidate faces based on how similar they are to a target face. The aim is to estimate the subjective dissimilarity value for each face pair, where dissimilarity is measured as a floating point number between 0 and 1. 

The subject's dissimilarity space is represented by a 5-dimensional embedding, which we generate by passing a dissimilarity matrix to scikit-learn's [multidimensional scaling](https://scikit-learn.org/stable/modules/manifold.html#multidimensional-scaling) (MDS) `fit_transform` algorithm. The initial dissimilarity matrix is estimated based on the responses the subject provides in burn-in trials where the candidate faces, also known as the *body*, are selected at random. Outside of burn-in trials, the body is chosen by using a combination of algorithms based off of, and partially sourced from, **‌Active Ordinal Querying for Tuplewise Similarity Learning** (Canal et al., 2019). The output embedding from the MDS is passed to a body selector, which selects candidates that will maximize information gained at a given trial with a certain target face. For more information on the body selector algorithm, refer to Canal et al. 2019. 

### Code flow
1. Burn-in iterations, where candidates are chosen at random, are used to seed the initial dissimilarity matrix.
2. A metric MDS is run on the output (dissimilarity matrix) of the burn-in iterations. We use a nonmetric MDS to fill in the missing cells of the dissimimilarity matrix prior to running the metric MDS (*Note: In the pilot, we didn't do this. We only applied the nonmetric MDS and directly used its embeddings)
3. For each iteration:
	1. For each face in the dataset:
		1. Run the body selector where this face is the target face.
		2. Show the target face and candidate faces chosen by the body selector and have the subject rank the candidate faces.
	2. Generate a new dissimilarity matrix based on all the ranking data collected up to this point.
	3. Run metric MDS `fit_transform` on the new dissimilarity matrix, using the embedding output of the previous MDS as the seed. We fill in the missing cells, similar to 2, prior to running the metric MDS (*Note: In the pilot, we ran the metric MDS without filling in the missing cells; The value of the missing cells was set to zero)
4. Find all remaining face pairs in the dissimilarity matrix which have no data associated with them, and run backfill trials to fill in missing data using the process described in (3).
5. Save the dissimilarity matrix and the embeddings from the experiment for later use.

### Dissimilarity matrix formula
Each trial is segmented into sets of three, consisting of the target face and a combination of two of the candidate faces. Within each set, the face that ranked lower is marked as the odd face. Subsequently, the dissimilarity value between a given pair *x* and *y* is calculated as follows. The instances that *x* and *y* were compared, where either of them was the target face, are selected. The ratio of instances where one of them was the odd face is calculated as the dissimilarity value. We added 0.5 to both the numerator and the denominator when calculating this ratio to avoid getting a dissimilarity value of zero (only the diagonal value of the dissimilarity matrix should be zero) (*Note: in the pilot, we added 2 instead of 0.5. 0.5 is a better choice, so we use 0.5 in the main code) 

It is noteworthy that in the code, we first calculated the similarity value (i.e., the ratio where none of the faces was marked as the odd face) and then calculated the dissimilarity value by subtracting one from the similarity value. 

### Logging
The PsychoPy library automatically logs an `info.log`, which records experiment parameters and current machine parameters (the window, for example), as well as created objects and the location of mouse clicks including mouse down and mouse up. `warn.log` records the information from `info.log` that is at the `WARNING` level for debugging purposes. A `psychopy.log.csv` file is also created, which is currently not used.

Aside from the automatic logging provided by PsychoPy, logging is also done manually on each click to `click_data.csv` and per each iteration to `run_data.csv`. We also output the actual dissimilarity matrix `dissim_matrix.csv`, the output embedding `output_embedding.csv`, and the dissimilarity matrix generated from the output embedding `dissim_matrix_from_embedding.csv`. All of these are written as CSV files to the output directory after each iteration (step `3` above, i.e. one full cycle of each face in the dataset).

#### `click_data.csv`
This tracks the iteration number, trial number, click time, click position, as well as the clicked stim and what the target and candidate stims were. The default click tracking in `info.log` was not enough for our use case as it only tracks click position. The iteration at the end of the experiment, where missing values are filled in the dissimilarity matrix, is treated as the last numerical iteration in the experiment (`i+1`).

#### `run_data.csv`
This tracks data about the dissimilarity matrix change over time. Currently in production, the only metric we track with this log is `change_sim_matrix`, which is the change between the current dissimilarity matrix and the previous dissimilarity matrix per iteration. This is relevant because if the change is below `0.5`, which was set based on data from our pilot study, we immediately end step `3` of the experiment and move on to filling missing values in the dissimilarity matrix. At this point, the matrix is considered to be converged, so further iterations would not be helpful to gather more similarity data.

In testing, when there is a known `target_matrix` passed to the algorithm, this log also tracks the change correlation of the embedding and the matrix generated from the embedding with the known `target_matrix`. 

### PsychoPy
This experiment runs on PsychoPy 2023, using Python version 3.8. 

## Collected data
This folder contains the data collected from the “subjective similarity judgment task" and the “near-threshold discrimination task”

## Analysis code 
This folder contains the MATLAB codes for visualizing and analyzing the data.

**VisualizeTheStaircasesInTheDiscriminationTask.m**: This code visualizes all the interleaved staircases ran on a subject, in a single plot with subplots showcasing each pair’s staircase. Also, it prints the data quality check for each participant (i.e., the number of staircases with less than 3 downs in their last 20 trials). 

**VisualizeTheSubjectiveSimilarityData**: This code prints the dissimilarity matrix (derived from the embeddings), and also visualizes it in a 2D-space by applying a 2D metric-MDS. The 2D space is rotated so that the first face (face01) is always located in x<0, y=0 coordinate. This code also displays the data quality check for each participant (i.e., the correlation between the dissimilarity matrix derived from the first-half and the second-half of trials.  

**MainAnalysis**: This code applies all the analysis described in our paper and makes the plots shown in our pilot result figures.

## Prepare Faces and Morphs 
We used the Basal Face Model (BFM) in our study to generate the faces. Our code is based off of the BFM model shared here https://faces.dmi.unibas.ch/bfm/index.php?nav=1-2&id=downloads by Prof. Dr. T. Vetter. 

**Generate_Faces_And_Morphs**: The first part of the code generates 30 faces semi-randomly from the BFM space as described in our paper. The second part of the code generates 1000 equally spaced morphs between any selected two faces from the 30 faces inside the “faces” folder (the faces used in our study). The two faces are selected by **Face1_ID** and **Face2_ID** variables in the code.
