# Subjective-Dissimilarity-and-Discrimination-Capacity 
 
This is the repository for the paper **Is subjective perceptual similarity metacognitive?** It is broken down into several directories, listed below. Each section will be described in more detail.

1. **Analysis Code** - Used for analyzing and making charts from the collected data.
2. **Collected Data** - Log files gathered from subjects while running the experiment.
3. **Near Threshold Discrimination Task/src** - Source code for the near-threshold discrimination task.
4. **Prepare Faces and Morphs** - Source code used to prepare the faces and morphs for the tasks.
5. **Subjective Similarity Judgment Task** - Source code for the subjective similarity judgment task.

The **pilot** folder contains all the codes and materials used in running our pilot study (N = 4 participants), all the data collected, and the analysis code ran on the data. 
The **Main** folder contains all the codes and materials that will be used in the main study. 
## Near Threshold Discrimination Task
The near-threshold discrimination task is an interleaved staircase task where subjects discriminate between morphs of selected face pairs. Each staircase represents one face pair with 1000 morphs between them. Each face is assigned an integer ID. For example, for the face pair `1-28`, `1-28.1` represents the first morph for this pair, which is the closest to face 1. Similarly, `1-28.1000` is the 1000th morph for this pair, which is the closet to face 28. In each iteration, the staircase shows three faces. It randomly chooses a morph *n*, and shows the morph with ID `n` twice. It also stores an integer distance *k*, also known as the intensity, to use for each iteration, and shows a morph which is *k* away from the face *n*, i.e. `n±k`, once. Whether the applied intensity is positive or negative is chosen at random. The range from which *n* is randomly chosen is constrained such that `n±k` will always be between 1 and 1000. The intensity is controlled by a set of rules passed to `StairHandlerGetIntensity`, which in this experiment specifies a 2-down/1-up staircase with decreasing step sizes upon reversals. 

The experiment tests multiple face pairs at once. Each of the face pairs is represented by one staircase, and these staircases are interleaved such that they are shown in a random sequence to the subject. In every iteration, each staircase is shown once. At the end of the iteration, the order of the staircases is shuffled. Then, the next iteration begins. This process is repeated until the number of iterations `exp_info["n_trials"]` is hit.

### Logging
Logging is done manually, with both an `experiment.csv` log which records information about each click, and an individual log per staircase which tracks responses, reversals, and intensities for the individual staircase.

The `experiment.csv` log is generated by saving information from every click to a list object `experiment_log_tracker`, which is written to a CSV at the end of each iteration. 

The staircase log is handled by the `StaircaseLogger` class, which writes reversals and responses. This is also written at the end of each iteration. Note that the staircase log is written with the labels as rows, while the `experiment.csv` log is written with the labels as columns. This was done because the built-in PsychoPy staircase logging uses row-based labeling.

### PsychoPy
This experiment runs on PsychoPy 2023, using Python version 3.8. 

## Subjective Similarity Judgment Task
The subjective similarity judgment task is a similarity task where subjects rank candidate faces based on how similar they are to a target face. The aim is to estimate the subjective dissimilarity value for each face pair, where dissimilarity is measured as a floating point number between 0 and 1. 

The subject's dissimilarity space is represented by a 5-dimensional embedding, which we generate by passing a dissimilarity matrix to scikit-learn's [multidimensional scaling](https://scikit-learn.org/stable/modules/manifold.html#multidimensional-scaling) (MDS) `fit_transform` algorithm. The initial dissimilarity matrix is estimated based on the responses the subject provides in burn-in trials where the candidate faces, also known as the *body*, are selected at random. Outside of burn-in trials, the body is chosen by using a combination of algorithms based off of, and partially sourced from, **‌Active Ordinal Querying for Tuplewise Similarity Learning** (Canal, 2019). The output embedding from the MDS is passed to a body selector, which selects candidates that will maximize information gained at a given trial with a certain target face. For more information on the body selector algorithm, refer to Canal 2019. 

### Code flow
1. Burn-in iterations, where candidates are chosen at random, are used to seed the initial dissimilarity matrix.
2. An initial MDS is run on the output of the burn-in iterations. This initial MDS uses non metric MDS to account for the large number of missing values (i.e., the pairs with no ranking responses).
3. For each iteration:
	1. For each face in the dataset:
		1. Run the body selector where this face is the target face.
		2. Show the target face and candidate faces chosen by the body selector and have the subject rank the candidate faces.
	2. Generate a new dissimilarity matrix based on all the rankings data collected to this point
	3. Run metric MDS `fit_transform` on the new dissimilarity matrix, using the embedding output of the previous MDS as the seed. We use metric for all non burn-in iterations because it preserves the actual pairwise dissimilarity distance. Also, there are fewer zeros as a result of the burn-in iterations, and we can use the previous MDS as the seed.
4. Find all remaining face pairs in the dissimilarity matrix which have no data associated with them, and run backfill trials to fill in missing data using the process described in (3).
5. Save the dissimilarity matrix and the embeddings from the experiment for later use.

### Dissimilarity matrix formula
Each trial is segmented into sets of three, consisting of the target face and a combination of two of the candidate faces. Within each set, the face that ranked lower is marked as the odd face. Subsequently, the dissimilarity value between a given pair *x* and *y* is calculated as follows. The instances that *x* and *y* were compared, where either of them was the target face, are selected. The ratio of instances where one of them was the odd face is calculated as the dissimilarity value. Two non-tested sets with obvious outcomes when one of the faces repeats is also considered in this calculation. This fundamentally involves adding 2 to both the numerator and the denominator when calculating the ratio. 

It is noteworthy that in the code, we first calculated the similarity value (i.e., the ratio where none of the faces was marked as the odd face) and then calculated the dissimilarity value by subtracting one from the similarity value. 

### Logging
**“Add the logging info please”**
### PsychoPy
This experiment runs on PsychoPy 2023, using Python version 3.8. 

## Collected data
This folder contains the data collected from the “subjective similarity judgment task" and the “near-threshold discrimination task”

## Analysis code 
This folder contains the MATLAB codes for visualizing and analyzing the data.

**VisualizeTheStaircasesInTheDiscriminationTask.m**: This code visualizes all the interleaved staircases ran on a subject, in a single plot with subplots showcasing each pair’s staircase. 

**VisualizeTheSubjectiveSimilarityData**: This code prints the dissimilarity matrix (derived from the embeddings), and also visualizes it in a 2D-space by applying a 2D metric-MDS. The 2D space is rotated so that the first face (face01) is always located in x<0, y=0 coordinate.  

**MainAnalysis**: This code applies all the analysis described in our paper and makes the plots shown in our pilot result figures.

## Prepare Faces and Morphs 
We used the Basal Face Model (BFM) in our study to generate the faces. Our code is based off of the BFM model shared here https://faces.dmi.unibas.ch/bfm/index.php?nav=1-2&id=downloads by Prof. Dr. T. Vetter. 

**Generate_Faces_And_Morphs**: The first part of the code generates 30 faces semi-randomly from the BFM space as described in our paper. The second part of the code generates 1000 equally spaced morphs between any selected two faces from the 30 faces inside the “faces” folder (the faces used in our study). The two faces are selected by **Face1_ID** and **Face2_ID** variables in the code.

  
   

